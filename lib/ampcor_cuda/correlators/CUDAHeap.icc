// -*- c++ -*-
//
// michael a.g. aïvázis <michael.aivazis@para-sim.com>
// (c) 1998-2020 all rights reserved


// code guard
#if !defined(ampcor_cuda_correlators_CUDAHeap_icc)
#error this file contains implementation details for ampcor::cuda::correlators::CUDAHeap
#else


// metamethods
// constructor
template <class T, bool isConst>
ampcor::cuda::correlators::CUDAHeap<T, isConst>::
CUDAHeap(cell_count_type cells) :
    // initialize with a {nullptr} and replace it
    _data{ nullptr },
    _cells{ cells }
{
    // grab a spot
    pointer data = nullptr;
    // compute the memory footprint
    auto footprint = cells * sizeof(value_type);
    // allocate memory
    auto status = cudaMallocManaged(&data, footprint);
    // if something went wrong
    if (status != cudaSuccess) {
        // make a channel
        pyre::journal::error_t error("ampcor.cuda");
        // complain
        error
            << "while allocating " << footprint << " bytes of device memory: "
            << pyre::journal::newline
            << cudaGetErrorName(status) << " (" << status << ")"
            << pyre::journal::endl(__HERE__);
        // and bail
        throw std::bad_alloc();
    }

    // if all went well, make a deleter for CUDA allocated memory
    auto destructor = [footprint](auto ptr) {
        // attempt to free the block of memory
        auto status = cudaFree(ptr);
        // if something went wrong
        if (status != cudaSuccess) {
            // make a channel
            pyre::journal::error_t error("ampcor.cuda");
            // complain
            error
                << "while deallocating " << footprint << " bytes of device memory: "
                << pyre::journal::newline
                << cudaGetErrorName(status) << " (" << status << ")"
                << pyre::journal::endl(__HERE__);
        }
        // all done
        return;
    };

    // replace the {nullptr} with the new block
    _data.reset(data, destructor);
}


template <class T, bool isConst>
ampcor::cuda::correlators::CUDAHeap<T, isConst>::
CUDAHeap(handle_type handle, cell_count_type cells) :
    _data{ handle },
    _cells{ cells }
{}

// interface
// get the number of cells in the block
template <class T, bool isConst>
auto
ampcor::cuda::correlators::CUDAHeap<T, isConst>::
cells() const -> cell_count_type
{
    // easy
    return _cells;
}


// get the memory footprint of the block
template <class T, bool isConst>
auto
ampcor::cuda::correlators::CUDAHeap<T, isConst>::
bytes() const -> size_type
{
    // scale the number of cells by the cell size
    return cells() * sizeof(value_type);
}


// access to the data pointer
template <class T, bool isConst>
auto
ampcor::cuda::correlators::CUDAHeap<T, isConst>::
data() const -> pointer
{
    // return the raw data pointer
    return _data.get();
}


// get the shared pointer
template <class T, bool isConst>
auto
ampcor::cuda::correlators::CUDAHeap<T, isConst>::
handle() const -> handle_type
{
    // easy
    return _data;
}


// iterator support
template <class T, bool isConst>
auto
ampcor::cuda::correlators::CUDAHeap<T, isConst>::
begin() const -> pointer
{
    // the beginning of the block
    return data();
}


template <class T, bool isConst>
auto
ampcor::cuda::correlators::CUDAHeap<T, isConst>::
end() const -> pointer
{
    // one past the last cell in the block
    return data() + cells();
}


// data access
template <class T, bool isConst>
auto
ampcor::cuda::correlators::CUDAHeap<T, isConst>::
at(size_type pos) const -> reference
{
    // if the request is out of bounds
    if (pos >= cells()) {
        // make a channel
        pyre::journal::firewall_t channel("pyre.memory.bounds");
        // and complain
        channel
            << "out of bounds access:" << pyre::journal::newline
            << "  index " << pos << " must be less than " << cells() << pyre::journal::newline
            << "  in ampcor::cuda::correlators::heap_t::operator[]" << pyre::journal::newline
            << "  with a block on the heap at " << data()
            << pyre::journal::endl(__HERE__);
        // unreachable, unless the user has marked this error as non-fatal
        // clamp {pos} to the last element in the block
        pos = cells() - 1;
    }

    // return a reference to the cell at {pos}
    return _data[pos];
}


template <class T, bool isConst>
auto
ampcor::cuda::correlators::CUDAHeap<T, isConst>::
operator [] (size_type pos) const -> reference
{
    // return a reference to the cell at {pos}
    return _data[pos];
}


#endif

// end of file
